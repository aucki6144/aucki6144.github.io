<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>归档：TTS 常用数据集 | Shiranai Blog</title><meta name="author" content="Liu"><meta name="copyright" content="Liu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="归档：TTS 常用数据集  This post will be updated frequently, depending more datasets being testified.  Chinese-Mandarin 普通话 AISHELL-3 地址：https:&#x2F;&#x2F;www.aishelltech.com&#x2F;aishell_3 希尔贝壳中文普通话语音数据库AISHELL-3的语音时长为85小时8">
<meta property="og:type" content="article">
<meta property="og:title" content="归档：TTS 常用数据集">
<meta property="og:url" content="http://aucki6144.github.io/2023/07/12/TTS-%E6%95%B0%E6%8D%AE%E9%9B%86/index.html">
<meta property="og:site_name" content="Shiranai Blog">
<meta property="og:description" content="归档：TTS 常用数据集  This post will be updated frequently, depending more datasets being testified.  Chinese-Mandarin 普通话 AISHELL-3 地址：https:&#x2F;&#x2F;www.aishelltech.com&#x2F;aishell_3 希尔贝壳中文普通话语音数据库AISHELL-3的语音时长为85小时8">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://aucki6144.github.io/img/avatar.png">
<meta property="article:published_time" content="2023-07-12T09:11:59.000Z">
<meta property="article:modified_time" content="2023-09-18T09:12:39.361Z">
<meta property="article:author" content="Liu">
<meta property="article:tag" content="TTS">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://aucki6144.github.io/img/avatar.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://aucki6144.github.io/2023/07/12/TTS-%E6%95%B0%E6%8D%AE%E9%9B%86/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '归档：TTS 常用数据集',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-09-18 17:12:39'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/default_top.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Shiranai Blog"><img class="site-icon" src="/img/favicon.png"/><span class="site-name">Shiranai Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">归档：TTS 常用数据集</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-07-12T09:11:59.000Z" title="发表于 2023-07-12 17:11:59">2023-07-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-09-18T09:12:39.361Z" title="更新于 2023-09-18 17:12:39">2023-09-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Note/">Note</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="归档：TTS 常用数据集"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="归档：TTS-常用数据集">归档：TTS 常用数据集</h2>
<blockquote>
<p>This post will be updated frequently, depending more datasets being testified.</p>
</blockquote>
<h3 id="Chinese-Mandarin-普通话">Chinese-Mandarin 普通话</h3>
<h4 id="AISHELL-3">AISHELL-3</h4>
<p>地址：<a target="_blank" rel="noopener" href="https://www.aishelltech.com/aishell_3">https://www.aishelltech.com/aishell_3</a></p>
<p>希尔贝壳中文普通话语音数据库AISHELL-3的语音时长为85小时<strong>88035句</strong>，可做为多说话人合成系统。录制过程在安静室内环境中， 使用高保真麦克风（44.1kHz，16bit）。218名来自中国不同口音区域的发言人参与录制。专业语音校对人员进行拼音和韵律标注，并通过严格质量检验，此数据库音字确率在98%以上。</p>
<p>AISHELL-3 is a large-scale and high-fidelity multi-speaker Mandarin speech corpus which could be used to train multi-speaker Text-to-Speech (TTS) systems. The corpus contains roughly 85 hours of emotion-neutral recordings spoken by 218 native Chinese mandarin speakers and total <strong>88035 utterances</strong>. Their auxiliary attributes such as gender, age group and native accents are explicitly marked and provided in the corpus. Accordingly, transcripts in Chinese character-level and pinyin-level are provided along with the recordings. The  word &amp; tone transcription accuracy rate is above 98%, through professional speech annotation and strict quality inspection for tone and prosody.</p>
<hr>
<h3 id="English-英语">English 英语</h3>
<h4 id="LJ-Speech">LJ Speech</h4>
<p>地址：<a target="_blank" rel="noopener" href="https://keithito.com/LJ-Speech-Dataset/">https://keithito.com/LJ-Speech-Dataset/</a></p>
<p>The LJ Speech Dataset: This is a public domain speech dataset consisting of 13,100 short audio clips of a single speaker reading passages from 7 non-fiction books. A transcription is provided for each clip. Clips vary in length from 1 to 10 seconds and have a total length of approximately 24 hours.</p>
<h4 id="LibriTTS">LibriTTS</h4>
<p>地址：<a target="_blank" rel="noopener" href="https://research.google/resources/datasets/libri-tts/">https://research.google/resources/datasets/libri-tts/</a></p>
<p>LibriTTS is a multi-speaker English corpus of approximately 585 hours of read English speech at 24kHz sampling rate. The LibriTTS corpus is designed for TTS research. It is derived from the original materials (mp3 audio files from LibriVox and text files from Project Gutenberg) of the LibriSpeech corpus.</p>
<p>The main differences from the LibriSpeech corpus are listed below:</p>
<ol>
<li>The audio files are at 24kHz sampling rate.</li>
<li>The speech is split at sentence breaks.</li>
<li>Both original and normalized texts are included.</li>
<li>Contextual information (e.g., neighbouring sentences) can be extracted.</li>
<li>Utterances with significant background noise are excluded.</li>
</ol>
<hr>
<h3 id="Multi-Language">Multi Language</h3>
<h4 id="Emotional-Speech-Database-ESD">Emotional Speech Database (ESD)</h4>
<p>地址：<a target="_blank" rel="noopener" href="https://hltsingapore.github.io/ESD/">https://hltsingapore.github.io/ESD/</a></p>
<p>ESD is an Emotional Speech Database for voice conversion research. The ESD database consists of 350 parallel utterances spoken by 10 native English and 10 native Chinese speakers and covers 5 emotion categories (neutral, happy, angry, sad and surprise). More than 29 hours of speech data were recorded in a controlled acoustic environment. The database is suitable for multi-speaker and cross-lingual emotional voice conversion studies.</p>
<hr>
<h3 id="Multimodality">Multimodality</h3>
<h4 id="M3ED">M3ED</h4>
<p>论文：<a target="_blank" rel="noopener" href="https://aclanthology.org/2022.acl-long.391.pdf">https://aclanthology.org/2022.acl-long.391.pdf</a></p>
<p>下载：<a target="_blank" rel="noopener" href="https://github.com/AIM3-RUC/RUCM3ED">https://github.com/AIM3-RUC/RUCM3ED</a></p>
<p>M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database. ACL 2022</p>
<p>In this work, we propose a multi-modal, multiscene, and multi-label emotional dialogue dataset, M3ED, for multimodal emotion recognition in conversations. Compared to MELD, the currently largest multimodal dialogue dataset for emotion recognition, M3ED is larger (24,449 vs. 13,708 utterances), more diversified (56 different TV series vs. only one TV series Friends), with higher-quality (balanced performance across all three modalities), and containing blended emotions annotation which is not available in MELD. M3ED is the first multimodal emotion dialogue dataset in Chinese, which can serve as a valuable addition to the affective computing community and promote the research of cross-culture emotion analysis and recognition. Furthermore, we propose a general Multimodal Dialog-aware Interaction framework, which considers multimodal fusion, temporal-context modeling, and speaker interactions modeling, and achieves the state-of-the-art performance. We also propose several interesting future exploration directions based on the M3ED dataset.</p>
<h4 id="MELD">MELD</h4>
<p>地址：<a target="_blank" rel="noopener" href="https://affective-meld.github.io/">https://affective-meld.github.io/</a></p>
<p>Multimodal EmotionLines Dataset (MELD) has been created by enhancing and extending EmotionLines dataset. MELD contains the same dialogue instances available in EmotionLines, but it also encompasses audio and visual modality along with text. MELD has more than 1400 dialogues and 13000 utterances from Friends TV series. Multiple speakers participated in the dialogues. Each utterance in a dialogue has been labeled by any of these seven emotions – Anger, Disgust, Sadness, Joy, Neutral, Surprise and Fear. MELD also has sentiment (positive, negative and neutral) annotation for each utterance.</p>
<h4 id="MOSEI">MOSEI</h4>
<p>地址：<a target="_blank" rel="noopener" href="http://multicomp.cs.cmu.edu/resources/cmu-mosei-dataset/">http://multicomp.cs.cmu.edu/resources/cmu-mosei-dataset/</a></p>
<p>CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) dataset is the largest dataset of multimodal sentiment analysis and emotion recognition to date. The dataset contains more than 23,500 sentence utterance videos from more than 1000 online YouTube speakers. The dataset is gender balanced. All the sentences utterance are randomly chosen from various topics and monologue videos. The videos are transcribed and properly punctuated.</p>
<h4 id="IEMOCAP">IEMOCAP</h4>
<p>地址：<a target="_blank" rel="noopener" href="https://sail.usc.edu/iemocap/index.html">https://sail.usc.edu/iemocap/index.html</a></p>
<p>The Interactive Emotional Dyadic Motion Capture (IEMOCAP) database is an acted, multimodal and multispeaker database, recently collected at <a target="_blank" rel="noopener" href="http://sail.usc.edu/">SAIL</a> lab at <a target="_blank" rel="noopener" href="http://www.usc.edu/">USC</a>. It contains approximately 12 hours of audiovisual data, including video, speech, motion capture of face, text transcriptions. It consists of dyadic sessions where actors perform improvisations or scripted scenarios, specifically selected to elicit emotional expressions. IEMOCAP database is annotated by multiple annotators into categorical labels, such as anger, happiness, sadness, neutrality, as well as dimensional labels such as valence, activation and dominance. The detailed motion capture information, the interactive setting to elicit authentic emotions, and the size of the database make this corpus a valuable addition to the existing databases in the community for the study and modeling of multimodal and expressive human communication.</p>
<hr>
<h3 id="Apart-From-Databases">Apart From Databases</h3>
<p>About the preprocess of data using MFA, please check out this post of mine: <a href="https://aucki6144.github.io/2023/09/10/MFA/">MFA: Montreal Forced Aligner</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://aucki6144.github.io">Liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://aucki6144.github.io/2023/07/12/TTS-%E6%95%B0%E6%8D%AE%E9%9B%86/">http://aucki6144.github.io/2023/07/12/TTS-%E6%95%B0%E6%8D%AE%E9%9B%86/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://aucki6144.github.io" target="_blank">Shiranai Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/TTS/">TTS</a></div><div class="post_share"><div class="social-share" data-image="/img/avatar.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/07/20/kotlin1-lambda/" title="Kotlin：Lambda编程（补档）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Kotlin：Lambda编程（补档）</div></div></a></div><div class="next-post pull-right"><a href="/2023/06/25/lenet/" title="Implement USPS Handwritten Digits Classification with Pytorch"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Implement USPS Handwritten Digits Classification with Pytorch</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/09/16/FastSpeech2%E7%AC%94%E8%AE%B0/" title="FastSpeech2 论文笔记（不包含FastSpeech2s）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-16</div><div class="title">FastSpeech2 论文笔记（不包含FastSpeech2s）</div></div></a></div><div><a href="/2023/09/17/Fastspeech-with-emotion-control/" title="TTS 情感控制：Fine-Grained Emotional Control of Text-To-Speech"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-17</div><div class="title">TTS 情感控制：Fine-Grained Emotional Control of Text-To-Speech</div></div></a></div><div><a href="/2023/09/18/Emospeech/" title="EmoSpeech：Guiding FastSpeech2 Towards Emotional Text to Speech"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-18</div><div class="title">EmoSpeech：Guiding FastSpeech2 Towards Emotional Text to Speech</div></div></a></div><div><a href="/2023/09/10/MFA/" title="MFA（Montreal Forced Aligner）简记"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-10</div><div class="title">MFA（Montreal Forced Aligner）简记</div></div></a></div><div><a href="/2023/09/16/NaturalSpeech2%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" title="论文笔记：NaturalSpeech2"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-16</div><div class="title">论文笔记：NaturalSpeech2</div></div></a></div><div><a href="/2023/06/07/TTS1/" title="论文笔记：TTS Key Components"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-07</div><div class="title">论文笔记：TTS Key Components</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Liu</div><div class="author-info__description">Majoring Computer Science in Harbin Institute of Technology (HIT), Shenzhen. Learning TTS and Electron.</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/aucki6144"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/aucki6144" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:aucki6144@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BD%92%E6%A1%A3%EF%BC%9ATTS-%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.</span> <span class="toc-text">归档：TTS 常用数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Chinese-Mandarin-%E6%99%AE%E9%80%9A%E8%AF%9D"><span class="toc-number">1.1.</span> <span class="toc-text">Chinese-Mandarin 普通话</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#AISHELL-3"><span class="toc-number">1.1.1.</span> <span class="toc-text">AISHELL-3</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#English-%E8%8B%B1%E8%AF%AD"><span class="toc-number">1.2.</span> <span class="toc-text">English 英语</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#LJ-Speech"><span class="toc-number">1.2.1.</span> <span class="toc-text">LJ Speech</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LibriTTS"><span class="toc-number">1.2.2.</span> <span class="toc-text">LibriTTS</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multi-Language"><span class="toc-number">1.3.</span> <span class="toc-text">Multi Language</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Emotional-Speech-Database-ESD"><span class="toc-number">1.3.1.</span> <span class="toc-text">Emotional Speech Database (ESD)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multimodality"><span class="toc-number">1.4.</span> <span class="toc-text">Multimodality</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#M3ED"><span class="toc-number">1.4.1.</span> <span class="toc-text">M3ED</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MELD"><span class="toc-number">1.4.2.</span> <span class="toc-text">MELD</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MOSEI"><span class="toc-number">1.4.3.</span> <span class="toc-text">MOSEI</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#IEMOCAP"><span class="toc-number">1.4.4.</span> <span class="toc-text">IEMOCAP</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Apart-From-Databases"><span class="toc-number">1.5.</span> <span class="toc-text">Apart From Databases</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/11/15/cluster/" title="机器学习：无监督学习">机器学习：无监督学习</a><time datetime="2023-11-15T10:14:51.000Z" title="发表于 2023-11-15 18:14:51">2023-11-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/11/15/LinearClassification/" title="机器学习：线性分类器">机器学习：线性分类器</a><time datetime="2023-11-15T08:02:12.000Z" title="发表于 2023-11-15 16:02:12">2023-11-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/19/electron1/" title="Electron in Action：Electron Note 1">Electron in Action：Electron Note 1</a><time datetime="2023-09-19T14:16:31.000Z" title="发表于 2023-09-19 22:16:31">2023-09-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/19/nextgpt/" title="NExT-GPT：Any-to-Any Multimodal LLM 任意到任意的多模态LLM系统">NExT-GPT：Any-to-Any Multimodal LLM 任意到任意的多模态LLM系统</a><time datetime="2023-09-19T10:09:10.000Z" title="发表于 2023-09-19 18:09:10">2023-09-19</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/18/Emospeech/" title="EmoSpeech：Guiding FastSpeech2 Towards Emotional Text to Speech">EmoSpeech：Guiding FastSpeech2 Towards Emotional Text to Speech</a><time datetime="2023-09-18T12:14:38.000Z" title="发表于 2023-09-18 20:14:38">2023-09-18</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Liu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to Shiranai Blog (SB?wwwww)</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '5ZsDktNIeF1l4RuXdjAEfyik-gzGzoHsz',
      appKey: 'BFDCUzxZrFhXRtAnnSwBN2KG',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>